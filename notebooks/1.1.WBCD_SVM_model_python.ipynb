{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d450a542",
   "metadata": {},
   "source": [
    "# WBCD dataset: Features selection and prediction of cancer diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfc3e1",
   "metadata": {},
   "source": [
    "On this notebook, we present the Python code to display the figure 2d and the supplementary table 2 of the [article](https://www.researchsquare.com/article/rs-1674043/v1).  \n",
    "\n",
    "The methodology was inspired by the following article:  \n",
    "\n",
    "Akay, F. (2009). Support vector machines combined with feature selection for breast cancer diagnosis. *Expert Systems with Applications*, 36(2), p. 3240-3247. doi: 10.1016/j.eswa.2008.01.009\n",
    "\n",
    "To test the performances of the original and the avatarized datasets, we performed 100 different train/test 70/30 splits with the same stratification.\n",
    "\n",
    "For each split : \n",
    "- We computed F-scores for each feature with the f_score function.\n",
    "- We trained a SVM model with the 5 best features selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d1d3b",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b121956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:38.862732Z",
     "start_time": "2021-12-20T11:05:37.978791Z"
    }
   },
   "outputs": [],
   "source": [
    "# General packages required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Graphical display packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import use\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning tools packages\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b3b5f",
   "metadata": {},
   "source": [
    "## Specific functions created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7159f6ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:38.984366Z",
     "start_time": "2021-12-20T11:05:38.981433Z"
    }
   },
   "outputs": [],
   "source": [
    "def round_spec(val, dec=2):\n",
    "    \"\"\"\n",
    "    Specific round format for quantitative variable\n",
    "    Input:\n",
    "        - val: continuous value\n",
    "        - dec: number of decimals for the value (2 by default)\n",
    "    Output:\n",
    "        - string with the value in the correct format\n",
    "    \"\"\"\n",
    "    return (\"{:.\" + str(dec) + \"f}\").format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b22106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:39.212566Z",
     "start_time": "2021-12-20T11:05:39.203468Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_score(X, y, val1=2, val2=4):\n",
    "    \"\"\"\n",
    "    Computation of F-score for each feature.\n",
    "    Input:\n",
    "        - X is the feature\n",
    "        - y is the ouput variable\n",
    "        - val1 and val2 are the two modalities taken by y\n",
    "\n",
    "    Output:\n",
    "        - F-score of the variable X compared to y\n",
    "    \"\"\"\n",
    "    X1 = X[y == val1]\n",
    "    X2 = X[y == val2]\n",
    "    mean_X = X.mean()\n",
    "    mean_X1 = X1.mean()\n",
    "    mean_X2 = X2.mean()\n",
    "    n_X1 = len(X1)\n",
    "    n_X2 = len(X2)\n",
    "    sum_X1 = ((X1 - mean_X1) ** 2).sum()\n",
    "    sum_X2 = ((X2 - mean_X2) ** 2).sum()\n",
    "    return ((mean_X1 - mean_X) ** 2 + (mean_X2 - mean_X) ** 2) / (\n",
    "        ((1 / (n_X1 - 1)) * sum_X1) + ((1 / (n_X2 - 1)) * sum_X2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50bc2717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:39.973304Z",
     "start_time": "2021-12-20T11:05:39.944021Z"
    }
   },
   "outputs": [],
   "source": [
    "def unique_SVM_model(\n",
    "    X_train, y_train, X_test, y_test, order, parameters, nb_var, njobs=11\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a SVM model by founding the best parameters and returns evaluation metrics.\n",
    "    Input:\n",
    "        - X_train, y_train, X_test, y_test: train/test datasets to train the SVM model\n",
    "        - order: vector of features' order resulting from F-scores' calculation\n",
    "        - parameters: set of parameters to test to have the best parameters in the ML model\n",
    "        - nb_var: number of features selected for the model\n",
    "\n",
    "    Output:\n",
    "        - best_params: parameters used to compute the best model\n",
    "        - cm: confusion matrix of the best model\n",
    "        - df_res: dataframe with performance metrics of the best model\n",
    "        - df_roc: dataframe to draw the ROC curve of the best model\n",
    "    \"\"\"\n",
    "    svc = SVC(probability=True)\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=njobs)\n",
    "    clf.fit(X_train[order[0:nb_var]], y_train)\n",
    "    best_params = clf.best_params_\n",
    "    cm = pd.crosstab(y_test, clf.predict(X_test[order[0:nb_var]]))\n",
    "    TP = cm.iloc[0, 0]\n",
    "    TN = cm.iloc[1, 1]\n",
    "    FP = cm.iloc[0, 1]\n",
    "    FN = cm.iloc[1, 0]\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN) * 100\n",
    "    specificity = TN / (TN + FP) * 100\n",
    "    ppv = TP / (TP + FP) * 100\n",
    "    npv = TN / (TN + FN) * 100\n",
    "    auc = metrics.roc_auc_score(\n",
    "        y_train, clf.predict_proba(X_train[order[0:nb_var]])[:, 1]\n",
    "    )\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        y_train, clf.predict_proba(X_train[order[0:nb_var]])[:, 1]\n",
    "    )\n",
    "    df_roc = pd.DataFrame({\"fpr\": fpr, \"tpr\": tpr, \"thresholds\": thresholds})\n",
    "    df_res = pd.DataFrame(\n",
    "        [accuracy, sensitivity, specificity, ppv, npv, auc],\n",
    "        index=[\"acc\", \"sens\", \"spec\", \"ppv\", \"npv\", \"auc\"],\n",
    "    )\n",
    "    return (best_params, cm, df_res, df_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d834b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_pipeline_results(df, name):\n",
    "\n",
    "    F1_scores = list()  # list of F1 score dataframe\n",
    "\n",
    "    predictions = list()  # list of prediction dataframe\n",
    "\n",
    "    order_features_data = [\n",
    "        \"Bare_Nuclei\",\n",
    "        \"Uniformity_of_Cell_Shape\",\n",
    "        \"Uniformity_of_Cell_Size\",\n",
    "        \"Bland_Chromatin\",\n",
    "        \"Clump_Thickness\",\n",
    "        \"Marginal_Adhesion\",\n",
    "        \"Normal_Nucleoli\",\n",
    "        \"Single_Epithelial_Cell_Size\",\n",
    "        \"Mitoses\",\n",
    "    ]\n",
    "\n",
    "    for seed in range(100):\n",
    "        # Train/test split of dataset\n",
    "        (\n",
    "            data_X_train_70,\n",
    "            data_X_test_30,\n",
    "            data_y_train_70,\n",
    "            data_y_test_30,\n",
    "        ) = train_test_split(\n",
    "            df.drop(\"Class\", axis=1),\n",
    "            df.Class,\n",
    "            train_size=0.7,\n",
    "            stratify=data.Class,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        # Feature selection\n",
    "        F1_score = data_X_train_70.apply(\n",
    "            lambda col: f_score(col, data_y_train_70, val1=0, val2=1), axis=0\n",
    "        )\n",
    "        F1_score = pd.DataFrame(F1_score)\n",
    "        F1_score[\"feature\"] = F1_score.index\n",
    "        F1_score[\"type\"] = name\n",
    "        F1_score = F1_score.reset_index(drop=True)\n",
    "\n",
    "        F1_scores.append(F1_score)\n",
    "\n",
    "        # SVM Model\n",
    "        (\n",
    "            best_params_data_A_70_5,\n",
    "            cm_data_A_70_5,\n",
    "            prediction,\n",
    "            df_roc_data_A_70_5,\n",
    "        ) = unique_SVM_model(\n",
    "            data_X_train_70,\n",
    "            data_y_train_70,\n",
    "            data_X_test_30,\n",
    "            data_y_test_30,\n",
    "            order_features_data,\n",
    "            parameters,\n",
    "            nb_var=5,\n",
    "            njobs=11,\n",
    "        )\n",
    "        prediction = pd.DataFrame(prediction)\n",
    "        prediction[\"perf\"] = prediction.index\n",
    "        prediction[\"type\"] = name\n",
    "        prediction = prediction.reset_index(drop=True)\n",
    "\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    predictions = pd.concat(predictions)\n",
    "    F1_scores = pd.concat(F1_scores)\n",
    "\n",
    "    # Reshape F1_scores\n",
    "    F1_scores[\"feature\"] = (\n",
    "        pd.Series(F1_scores[\"feature\"]).apply(lambda val: val.replace(\"_\", \" \")).values\n",
    "    )\n",
    "    F1_scores.columns = [\"F-score\", \"feature\", \"type\"]\n",
    "\n",
    "    return F1_scores, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e390d5d4",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4126aea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:42.691710Z",
     "start_time": "2021-12-20T11:05:42.680596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the color df containing colors combination\n",
    "colors = pd.read_csv(\"../color.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77cb0304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:43.055715Z",
     "start_time": "2021-12-20T11:05:43.050912Z"
    }
   },
   "outputs": [],
   "source": [
    "file_data = \"../datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af746e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:43.908662Z",
     "start_time": "2021-12-20T11:05:43.890246Z"
    }
   },
   "outputs": [],
   "source": [
    "# we load original data and avatar data with k = 20\n",
    "data = pd.read_csv(file_data + \"WBCD/breast_cancer_wisconsin.csv\")\n",
    "data = data.drop(\"Sample_code_number\", axis=1)\n",
    "avatar = pd.read_csv(file_data + \"/WBCD/breast_cancer_wisconsin_avatarized_k20.csv\")\n",
    "synthpop = pd.read_csv(file_data + \"/WBCD/wbcd_synthpop_base.csv\")\n",
    "ctgan = pd.read_csv(file_data + \"/WBCD/wbcd_CTGAN_base_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6787e73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:44.656954Z",
     "start_time": "2021-12-20T11:05:44.637568Z"
    }
   },
   "outputs": [],
   "source": [
    "data.Class = data.Class.replace(2, 0)\n",
    "data.Class = data.Class.replace(4, 1)\n",
    "\n",
    "avatar.Class = avatar.Class.replace(2, 0)\n",
    "avatar.Class = avatar.Class.replace(4, 1)\n",
    "\n",
    "synthpop.Class = synthpop.Class.replace(2, 0)\n",
    "synthpop.Class = synthpop.Class.replace(4, 1)\n",
    "\n",
    "ctgan.Class = ctgan.Class.replace(2, 0)\n",
    "ctgan.Class = ctgan.Class.replace(4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce7abb",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0ea208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:05:55.258363Z",
     "start_time": "2021-12-20T11:05:55.248871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters map for the SVM model\n",
    "map_object = map(lambda val: 2**val, list(range(-15, 3)))\n",
    "gamma_list = list(map_object)\n",
    "\n",
    "map_object = map(lambda val: 2**val, list(range(-5, 16)))\n",
    "C_list = list(map_object)\n",
    "\n",
    "parameters = {\"kernel\": [\"rbf\"], \"C\": C_list, \"gamma\": gamma_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64e594",
   "metadata": {},
   "source": [
    "## Analysis computation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1fa61",
   "metadata": {},
   "source": [
    "The following cell is time consuming (more than 80 minutes).\n",
    "To simplify the access to the paper figures, we saved the results obtained at the end of the following function in a dataframe that you can load after this cell.   \n",
    "Thus, the execution is not required.\n",
    "If you still want to compute it, change the variable **compute** from *False* to *True* at the first line of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11385856",
   "metadata": {},
   "source": [
    "### Original - Avatar comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e76a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The computation could be higher than 80 min - data has been saved in a data frame\n",
    "compute = False\n",
    "if compute:\n",
    "    datasets = [\n",
    "        (data, \"Original\"),\n",
    "        (avatar, \"Avatar\"),\n",
    "        (synthpop, \"Synthpop\"),\n",
    "        (ctgan, \"CT-GAN\"),\n",
    "    ]\n",
    "\n",
    "    comparative_f1_scores = []\n",
    "    comparative_predictions = []\n",
    "    for df, name in datasets:\n",
    "        print(\"dataset: \", name)\n",
    "        F1_scores, predictions = get_svm_pipeline_results(df, name)\n",
    "        comparative_f1_scores.append(F1_scores)\n",
    "        comparative_predictions.append(predictions)\n",
    "\n",
    "    comparative_f1_scores = pd.concat(comparative_f1_scores, ignore_index=True)\n",
    "    comparative_predictions = pd.concat(comparative_predictions, ignore_index=True)\n",
    "\n",
    "    comparative_f1_scores.to_csv(\n",
    "        \"../datasets/results_df/comparative_f1_scores.csv\", index=False\n",
    "    )\n",
    "    comparative_predictions.to_csv(\n",
    "        \"../datasets/results_df/comparative_predictions.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "83bfc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_f1_scores = pd.read_csv(\"../datasets/results_df/comparative_f1_scores.csv\")\n",
    "comparative_predictions = pd.read_csv(\n",
    "    \"../datasets/results_df/comparative_predictions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1b0b21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_f1_scores_avatar = comparative_f1_scores[\n",
    "    (comparative_f1_scores[\"type\"] == \"Original\")\n",
    "    | (comparative_f1_scores[\"type\"] == \"Avatar\")\n",
    "]\n",
    "comparative_f1_scores_synthpop = comparative_f1_scores[\n",
    "    (comparative_f1_scores[\"type\"] == \"Original\")\n",
    "    | (comparative_f1_scores[\"type\"] == \"Synthpop\")\n",
    "]\n",
    "comparative_f1_scores_ctgan = comparative_f1_scores[\n",
    "    (comparative_f1_scores[\"type\"] == \"Original\")\n",
    "    | (comparative_f1_scores[\"type\"] == \"CT-GAN\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6be130e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_predictions_avatars = comparative_predictions[\n",
    "    (comparative_predictions[\"type\"] == \"Original\")\n",
    "    | (comparative_predictions[\"type\"] == \"Avatar\")\n",
    "]\n",
    "comparative_predictions_synthpop = comparative_predictions[\n",
    "    (comparative_predictions[\"type\"] == \"Original\")\n",
    "    | (comparative_predictions[\"type\"] == \"Synthpop\")\n",
    "]\n",
    "comparative_predictions_ctgan = comparative_predictions[\n",
    "    (comparative_predictions[\"type\"] == \"Original\")\n",
    "    | (comparative_predictions[\"type\"] == \"CT-GAN\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d126cf0",
   "metadata": {},
   "source": [
    "\n",
    "## Supplemental table\n",
    "\n",
    "We computed prediction performances for each split for avatar and original data. \n",
    "Results are presented in table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f7d41525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T11:06:02.603445Z",
     "start_time": "2021-12-20T11:06:02.562839Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction_metrics(df):\n",
    "    # multiple accuracy and auc to get them in percentage\n",
    "    df.loc[df[\"perf\"] == \"acc\", \"0\"] *= 100\n",
    "    df.loc[df[\"perf\"] == \"auc\", \"0\"] *= 100\n",
    "\n",
    "    # perform stats ok classification metrics\n",
    "    prediction_metrics = df.groupby([\"perf\", \"type\"]).agg({\"0\": [\"mean\", \"std\"]})\n",
    "    prediction_metrics = prediction_metrics.reset_index()\n",
    "    prediction_metrics.columns = [\"Metric\", \"type\", \"mean\", \"std\"]\n",
    "    prediction_metrics[\"values\"] = (\n",
    "        prediction_metrics[\"mean\"].apply(round_spec, 3)\n",
    "        + \" (\\u00B1 \"\n",
    "        + prediction_metrics[\"std\"].apply(round_spec, 3)\n",
    "        + \")\"\n",
    "    )\n",
    "    prediction_metrics = prediction_metrics.pivot(\n",
    "        index=\"Metric\", columns=\"type\", values=\"values\"\n",
    "    )\n",
    "    prediction_metrics.columns = prediction_metrics.columns.values\n",
    "    prediction_metrics = prediction_metrics.reset_index(col_level=0)\n",
    "    prediction_metrics[\"Metric\"] = [\n",
    "        \"Accuracy\",\n",
    "        \"AUC\",\n",
    "        \"NPV\",\n",
    "        \"PPV\",\n",
    "        \"Sensitivy\",\n",
    "        \"Specificity\",\n",
    "    ]\n",
    "\n",
    "    return prediction_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "98fe2d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Avatar</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>97.04 (± 0.99)</td>\n",
       "      <td>96.58 (± 1.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUC</td>\n",
       "      <td>99.84 (± 0.12)</td>\n",
       "      <td>99.46 (± 0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NPV</td>\n",
       "      <td>96.07 (± 2.77)</td>\n",
       "      <td>96.08 (± 2.88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPV</td>\n",
       "      <td>97.60 (± 1.62)</td>\n",
       "      <td>96.85 (± 1.35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensitivy</td>\n",
       "      <td>97.87 (± 1.49)</td>\n",
       "      <td>97.88 (± 1.51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>95.69 (± 2.83)</td>\n",
       "      <td>94.35 (± 2.28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric          Avatar        Original\n",
       "0     Accuracy  97.04 (± 0.99)  96.58 (± 1.25)\n",
       "1          AUC  99.84 (± 0.12)  99.46 (± 0.25)\n",
       "2          NPV  96.07 (± 2.77)  96.08 (± 2.88)\n",
       "3          PPV  97.60 (± 1.62)  96.85 (± 1.35)\n",
       "4    Sensitivy  97.87 (± 1.49)  97.88 (± 1.51)\n",
       "5  Specificity  95.69 (± 2.83)  94.35 (± 2.28)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_metrics(comparative_predictions_avatars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7ae502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Original</th>\n",
       "      <th>Synthpop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>96.58 (± 1.25)</td>\n",
       "      <td>95.75 (± 1.29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUC</td>\n",
       "      <td>99.46 (± 0.25)</td>\n",
       "      <td>99.24 (± 0.58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NPV</td>\n",
       "      <td>96.08 (± 2.88)</td>\n",
       "      <td>95.34 (± 2.59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPV</td>\n",
       "      <td>96.85 (± 1.35)</td>\n",
       "      <td>95.99 (± 1.83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensitivy</td>\n",
       "      <td>97.88 (± 1.51)</td>\n",
       "      <td>97.28 (± 1.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>94.35 (± 2.28)</td>\n",
       "      <td>93.27 (± 2.96)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric        Original        Synthpop\n",
       "0     Accuracy  96.58 (± 1.25)  95.75 (± 1.29)\n",
       "1          AUC  99.46 (± 0.25)  99.24 (± 0.58)\n",
       "2          NPV  96.08 (± 2.88)  95.34 (± 2.59)\n",
       "3          PPV  96.85 (± 1.35)  95.99 (± 1.83)\n",
       "4    Sensitivy  97.88 (± 1.51)  97.28 (± 1.48)\n",
       "5  Specificity  94.35 (± 2.28)  93.27 (± 2.96)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_metrics(comparative_predictions_synthpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8b2f8998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>CT-GAN</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>99.21 (± 0.46)</td>\n",
       "      <td>96.58 (± 1.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUC</td>\n",
       "      <td>99.95 (± 0.04)</td>\n",
       "      <td>99.46 (± 0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NPV</td>\n",
       "      <td>99.09 (± 0.71)</td>\n",
       "      <td>96.08 (± 2.88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPV</td>\n",
       "      <td>99.36 (± 0.78)</td>\n",
       "      <td>96.85 (± 1.35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensitivy</td>\n",
       "      <td>98.86 (± 0.89)</td>\n",
       "      <td>97.88 (± 1.51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>99.49 (± 0.63)</td>\n",
       "      <td>94.35 (± 2.28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric          CT-GAN        Original\n",
       "0     Accuracy  99.21 (± 0.46)  96.58 (± 1.25)\n",
       "1          AUC  99.95 (± 0.04)  99.46 (± 0.25)\n",
       "2          NPV  99.09 (± 0.71)  96.08 (± 2.88)\n",
       "3          PPV  99.36 (± 0.78)  96.85 (± 1.35)\n",
       "4    Sensitivy  98.86 (± 0.89)  97.88 (± 1.51)\n",
       "5  Specificity  99.49 (± 0.63)  94.35 (± 2.28)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_metrics(comparative_predictions_ctgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b79c50c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T09:20:43.847137Z",
     "start_time": "2021-11-24T09:20:43.835872Z"
    }
   },
   "outputs": [],
   "source": [
    "# res_mean.to_csv('../datasets/results_df/supplemental_table_WBCD_synthpop.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85581776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('avatar-paper-igF8noez-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c38188a82a43ddc67be1f93bc84d9752accb86d7b4a60cc93d24ca38b0f9f969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
